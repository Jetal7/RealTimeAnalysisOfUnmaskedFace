# -*- coding: utf-8 -*-
"""FaceMaskKaggle_MobileNetV2ResNet50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GosC2sKPutB82jumgq0RJ-DfIhsWqzLR
"""

!pip install tensorflow
!pip install keras

import numpy as np
import os
import matplotlib.pyplot as plt
import sklearn
import imutils
from imutils import paths
import tensorflow as tf
from keras import activations

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input

from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img

from tensorflow.keras.utils import to_categorical

from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score

dataset = "/content/drive/MyDrive/FaceMaskClassifier/Dataset"
imagePaths=list(paths.list_images(dataset))

data = []
labels = []

for i in imagePaths:
  label = i.split(os.path.sep)[-2]
  labels.append(label)
  image = load_img(i,target_size=(224,224))
  image = img_to_array(image)
  image = preprocess_input(image)
  data.append(image)

data = np.array(data,dtype='float32')
labels=np.array(labels)

data.shape

labels

lb = LabelBinarizer()
labels = lb.fit_transform(labels)
labels = to_categorical(labels)

labels

train_X, test_X, train_Y, test_Y = train_test_split(data, labels, test_size = 0.20, random_state = 10, stratify= labels )

train_X.shape

train_Y.shape

test_X.shape

test_Y.shape

data_aug = ImageDataGenerator(rotation_range=20,
                         zoom_range=0.15,
                         width_shift_range=0.2,
                         height_shift_range=0.2,
                         shear_range=0.15,
                         horizontal_flip=True, 
                         vertical_flip=True,
                         fill_mode='nearest')

MobileNetV2_Model = MobileNetV2(weights = 'imagenet', include_top=False,input_tensor=Input(shape=(224,224,3)))

Model_1 = MobileNetV2_Model.output
Model_1 = AveragePooling2D(pool_size = (7,7))(Model_1)
Model_1 = Flatten(name='Flatten')(Model_1)
Model_1 = Dense(128,activation = 'relu')(Model_1)
Model_1 = Dropout(0.5)(Model_1)
Model_1 = Dense(2, activation='softmax')(Model_1)

model_1 = Model(inputs = MobileNetV2_Model.input, outputs = Model_1)

for layer in MobileNetV2_Model.layers:
  layer.trainable = False

learning_rate = 0.001
Epochs = 10
BS = 12

opt = Adam(lr = learning_rate, decay = learning_rate/Epochs)
model_1.compile(loss='binary_crossentropy',optimizer = opt, metrics=['accuracy'])

History_model_1 = model_1.fit(
    data_aug.flow(train_X,train_Y,batch_size=BS),
    steps_per_epoch = len(train_X)//BS,
    validation_data = (test_X,test_Y),
    validation_steps = len(test_X)//BS,
    epochs = Epochs
)

model_1.save(r'/content/drive/MyDrive/Model/mobilenetv2.model')

predict_model_1 = model_1.predict(test_X,batch_size = BS)
predict_model_1 = np.argmax(predict_model_1,axis = 1)
print(classification_report(test_Y.argmax(axis = 1), predict_model_1, target_names = lb.classes_))

print(confusion_matrix(test_Y.argmax(axis = 1), predict_model_1))

print('Accuracy:', accuracy_score(test_Y.argmax(axis = 1), predict_model_1))

accu_model_1 = History_model_1.history['accuracy']
val_acc_model_1 = History_model_1.history['val_accuracy']

plt.plot(accu_model_1, label="Accuracy")
plt.plot(val_acc_model_1)
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend(['Accuracy', 'val_accuracy'])
plt.plot(np.argmax(History_model_1.history["val_accuracy"]), np.max(History_model_1.history["val_accuracy"]), marker="x", color="r",
         label="best model")
plt.show()

plt.title("Learning curve")
plt.plot(History_model_1.history["loss"], label="loss")
plt.plot(History_model_1.history["val_loss"], label="val_loss")
plt.plot(np.argmin(History_model_1.history["val_loss"]), np.min(History_model_1.history["val_loss"]), marker="x", color="r",
         label="best model")
plt.xlabel("Epochs")
plt.ylabel("log_loss")
plt.legend();

"""## ResNet50"""

from keras.applications.resnet import ResNet50

resnet50_model = ResNet50(weights = 'imagenet', include_top=False,input_tensor=Input(shape=(224,224,3)))

Model_2 = resnet50_model.output
Model_2 = AveragePooling2D(pool_size = (7,7))(Model_2)
Model_2 = Flatten(name='Flatten')(Model_2)
Model_2 = Dense(128,activation = 'relu')(Model_2)
Model_2 = Dropout(0.5)(Model_2)
Model_2 = Dense(2, activation='softmax')(Model_2)

model_2 = Model(inputs = resnet50_model.input, outputs = Model_2)

for layer in resnet50_model.layers:
  layer.trainable = False

learning_rate = 0.001
Epochs = 10
BS = 12

opt = Adam(learning_rate, decay = learning_rate/Epochs)
model_2.compile(optimizer = opt, loss='binary_crossentropy', metrics=['accuracy'])

History_model_2 = model_2.fit(
    data_aug.flow(train_X,train_Y,batch_size=BS),
    steps_per_epoch = len(train_X)//BS,
    validation_data = (test_X,test_Y),
    validation_steps = len(test_X)//BS,
    epochs = Epochs)

model_2.save(r'/content/drive/MyDrive/FaceMaskClassifier/ResNet50Model')

predict_model_2 = model_2.predict(test_X,batch_size = BS)
predict_model_2 = np.argmax(predict_model_2,axis = 1)
print(classification_report(test_Y.argmax(axis = 1), predict_model_2, target_names = lb.classes_))

print(confusion_matrix(test_Y.argmax(axis = 1), predict_model_2))

print('Accuracy:', accuracy_score(test_Y.argmax(axis = 1), predict_model_2))

accu_model_2 = History_model_2.history['accuracy']
val_acc_model_2 = History_model_2.history['val_accuracy']

plt.plot(accu_model_1, label="Accuracy")
plt.plot(val_acc_model_2)
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend(['Accuracy', 'val_accuracy'])
plt.plot(np.argmax(History_model_2.history["val_accuracy"]), np.max(History_model_2.history["val_accuracy"]), marker="x", color="r",
         label="best model")
plt.show()

plt.title("Learning curve")
plt.plot(History_model_2.history["loss"], label="loss")
plt.plot(History_model_2.history["val_loss"], label="val_loss")
plt.plot(np.argmin(History_model_2.history["val_loss"]), np.min(History_model_2.history["val_loss"]), marker="x", color="r",
         label="best model")
plt.xlabel("Epochs")
plt.ylabel("log_loss")
plt.legend();